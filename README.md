# 🧠 Building LLM-Powered Applications with Open-Source Tools

## 📘 Course Overview

This self-paced MSc-level course teaches you how to build real-world applications using Large Language Models (LLMs) — entirely with **open-source tools**. You’ll gain hands-on experience with modern frameworks, pipelines, and deployment strategies, without depending on commercial APIs.

As generative AI transforms industries, the ability to design, deploy, and evaluate LLM-based solutions is a critical skill for software engineers. This course focuses on **practical workflows**, enabling you to create interactive, LLM-powered applications that are portable, customizable, and production-ready.

## 👨‍💻 Who This Course is For

This course is designed for **experienced software engineers and technical professionals** who are:

- Comfortable with **Python**, REST APIs, and backend/frontend basics
- New to AI/LLMs but curious to learn quickly
- Looking for **practical, code-driven workflows**, not academic theory

You do **not** need prior ML or data science experience. However, this course is **not suitable** for:
- Learners without any programming background
- Those seeking to **train large models from scratch**
- Those expecting coverage of deep mathematical theory

## 🎯 What You’ll Learn

By the end of the course, you’ll be able to:

- Run and use open-weight LLMs (e.g., LLaMA 2, Mistral, Phi-2)
- Apply prompt engineering techniques (zero-shot, few-shot, CoT)
- Generate and use embeddings for vector search
- Build Retrieval-Augmented Generation (RAG) pipelines
- Develop and deploy LLM apps with APIs and UIs
- Implement guardrails and evaluate model outputs
- (Optional) Explore quantization, fine-tuning, and agentic orchestration

## 🧩 Course Structure

The course consists of **8 hands-on modules** plus a **Capstone Project**, totaling **60–80 hours** of effort. Each module includes:

- A 6–12 hour time budget
- Required reading and lab-based resources
- One assignment to apply key skills
- Optional enrichment for advanced learners

It’s **asynchronous and self-paced**, ideal for solo learners or teams of 2–3.

## 🛠 Tools & Technologies Used

You’ll work with a rich ecosystem of **open-source tools**, including:

- **Hugging Face Transformers** (model loading, inference)
- **LangChain** and **LlamaIndex** (pipeline orchestration)
- **Vector databases**: Chroma, Qdrant, Weaviate
- **App frameworks**: FastAPI, Streamlit, Gradio
- **Containers**: Docker, Hugging Face Spaces, Colab
- (Optional) vLLM, LoRA, Guardrails AI, Rebuff

## 🔍 What to Expect

This is a **hands-on, application-focused** course. You will:

- Write Python code, build pipelines, and run real models
- Use **open-weight models** (no reliance on GPT APIs)
- Focus on **real use cases**, not research papers
- Learn modern LLM patterns like RAG, semantic search, and guardrails

## 🚫 What Not to Expect

To help set the right expectations, this course:

- Does **not cover deep math** or ML model training
- Does **not require GPU clusters** or enterprise-scale infra
- Does **not teach** general AI/ML theory or foundational algorithms
- Is **not for beginners in coding or Python**

## ⏱ Time Commitment & Pacing

- Total: **60–80 hours**
- Recommended pace: **6–8 hours/week** for 6–10 weeks
- Modular structure: Flexible order, milestone assignments
- Optional enrichment adds depth but isn’t required

## 🎓 Capstone Project

The course culminates in a **capstone design and prototype**:

- Build an **LLM-powered app** in a real domain (e.g. tutoring, productivity, customer support)
- Combine prompting, RAG, UI/API, and evaluation
- Include at least one evaluation mechanism and one guardrail
- This becomes a **portfolio-worthy deliverable**

## 🚀 Getting Started

**Prerequisites**:
- Working knowledge of Python and Git
- Ability to run Jupyter/Colab notebooks
- Basic familiarity with HTTP APIs and JSON

**Recommended Setup**:
- VS Code or Jupyter Notebook
- Google Colab or local Python environment
- Docker (for deployment modules)


---

Ready to start building? Clone this repo, explore the syllabus, and dive into Module 1!
